{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **MIAS Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from glob import glob\n",
    "\n",
    "# ---------------------- Setup Paths ----------------------\n",
    "input_folder = \"/content/drive/MyDrive/Colab Notebooks/archive - 2025-08-01T210435.399/MIAS\"  # This folder contains subfolders\n",
    "output_folder = \"/content/drive/MyDrive/Colab Notebooks/archive - 2025-08-01T210435.399/preprocessed_output\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# ---------------------- Preprocessing Functions ----------------------\n",
    "def resize_image(image, size=(256, 256)):\n",
    "    return cv2.resize(image, size)\n",
    "\n",
    "def normalize_image(image):\n",
    "    return cv2.normalize(image, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX)\n",
    "\n",
    "def remove_noise(image):\n",
    "    return cv2.GaussianBlur(image, (5, 5), 0)\n",
    "\n",
    "def remove_artifacts(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    _, thresh = cv2.threshold(gray, 240, 255, cv2.THRESH_BINARY)\n",
    "    cleaned = cv2.inpaint(image, thresh, 3, cv2.INPAINT_TELEA)\n",
    "    return cleaned\n",
    "\n",
    "def enhance_contrast(image):\n",
    "    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n",
    "    cl = clahe.apply(l)\n",
    "    enhanced = cv2.merge((cl, a, b))\n",
    "    return cv2.cvtColor(enhanced, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "# ---------------------- Preprocessing Pipeline ----------------------\n",
    "def preprocess_image(image_path):\n",
    "    original = cv2.imread(image_path)\n",
    "    resized = resize_image(original)\n",
    "    normalized = normalize_image(resized)\n",
    "    denoised = remove_noise(normalized)\n",
    "    artifact_removed = remove_artifacts(denoised)\n",
    "    contrast_enhanced = enhance_contrast(artifact_removed)\n",
    "\n",
    "    return {\n",
    "        \"Original\": original,\n",
    "        \"Resized\": resized,\n",
    "        \"Normalized\": normalized,\n",
    "        \"Denoised\": denoised,\n",
    "        \"Artifact Removed\": artifact_removed,\n",
    "        \"Contrast Enhanced\": contrast_enhanced\n",
    "    }\n",
    "\n",
    "# ---------------------- Run Batch Preprocessing ----------------------\n",
    "# \u2705 Collect all .png and .jpg images from all subfolders\n",
    "image_paths = glob(os.path.join(input_folder, \"**\", \"*.png\"), recursive=True)\n",
    "image_paths += glob(os.path.join(input_folder, \"**\", \"*.jpg\"), recursive=True)\n",
    "\n",
    "for img_path in image_paths:\n",
    "    # Get relative path to preserve subfolder structure\n",
    "    relative_path = os.path.relpath(img_path, input_folder)\n",
    "    output_path = os.path.join(output_folder, relative_path)\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "    results = preprocess_image(img_path)\n",
    "    final_output = results[\"Contrast Enhanced\"]\n",
    "    cv2.imwrite(output_path, final_output)\n",
    "\n",
    "print(f\"\u2705 {len(image_paths)} images preprocessed and saved to: {output_folder}\")\n",
    "\n",
    "# ---------------------- Show All Preprocessing Steps for Multiple Images ----------------------\n",
    "def show_all_images(image_paths, max_images=10):\n",
    "    for idx, img_path in enumerate(image_paths[:max_images]):\n",
    "        print(f\"\\n\ud83d\udd0d Displaying image {idx+1}/{min(max_images, len(image_paths))}: {os.path.basename(img_path)}\")\n",
    "        results = preprocess_image(img_path)\n",
    "\n",
    "        plt.figure(figsize=(18, 10))\n",
    "        for i, (title, image) in enumerate(results.items()):\n",
    "            plt.subplot(2, 3, i + 1)\n",
    "            plt.title(title)\n",
    "            plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "            plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# ---------------------- Show First Few Images ----------------------\n",
    "if image_paths:\n",
    "    show_all_images(image_paths, max_images=10)  # You can change 10 to any other number\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **BreaKHis Dataset**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **Preprocessing**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from glob import glob\n",
    "\n",
    "# ---------------------- Setup Paths ----------------------\n",
    "input_folder = \"/content/drive/MyDrive/Colab Notebooks/archive (97)/BreaKHis_v1/BreaKHis_v1/histology_slides/breast\"  # This folder contains subfolders\n",
    "output_folder = \"/content/drive/MyDrive/Colab Notebooks/archive (97)/preprocessed_output\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# ---------------------- Preprocessing Functions ----------------------\n",
    "def resize_image(image, size=(256, 256)):\n",
    "    return cv2.resize(image, size)\n",
    "\n",
    "def normalize_image(image):\n",
    "    return cv2.normalize(image, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX)\n",
    "\n",
    "def remove_noise(image):\n",
    "    return cv2.GaussianBlur(image, (5, 5), 0)\n",
    "\n",
    "def remove_artifacts(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    _, thresh = cv2.threshold(gray, 240, 255, cv2.THRESH_BINARY)\n",
    "    cleaned = cv2.inpaint(image, thresh, 3, cv2.INPAINT_TELEA)\n",
    "    return cleaned\n",
    "\n",
    "def enhance_contrast(image):\n",
    "    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n",
    "    cl = clahe.apply(l)\n",
    "    enhanced = cv2.merge((cl, a, b))\n",
    "    return cv2.cvtColor(enhanced, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "# ---------------------- Preprocessing Pipeline ----------------------\n",
    "def preprocess_image(image_path):\n",
    "    original = cv2.imread(image_path)\n",
    "    resized = resize_image(original)\n",
    "    normalized = normalize_image(resized)\n",
    "    denoised = remove_noise(normalized)\n",
    "    artifact_removed = remove_artifacts(denoised)\n",
    "    contrast_enhanced = enhance_contrast(artifact_removed)\n",
    "\n",
    "    return {\n",
    "        \"Original\": original,\n",
    "        \"Resized\": resized,\n",
    "        \"Normalized\": normalized,\n",
    "        \"Denoised\": denoised,\n",
    "        \"Artifact Removed\": artifact_removed,\n",
    "        \"Contrast Enhanced\": contrast_enhanced\n",
    "    }\n",
    "\n",
    "# ---------------------- Run Batch Preprocessing ----------------------\n",
    "# \u2705 Collect all .png and .jpg images from all subfolders\n",
    "image_paths = glob(os.path.join(input_folder, \"**\", \"*.png\"), recursive=True)\n",
    "image_paths += glob(os.path.join(input_folder, \"**\", \"*.jpg\"), recursive=True)\n",
    "\n",
    "for img_path in image_paths:\n",
    "    # Get relative path to preserve subfolder structure\n",
    "    relative_path = os.path.relpath(img_path, input_folder)\n",
    "    output_path = os.path.join(output_folder, relative_path)\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "    results = preprocess_image(img_path)\n",
    "    final_output = results[\"Contrast Enhanced\"]\n",
    "    cv2.imwrite(output_path, final_output)\n",
    "\n",
    "print(f\"\u2705 {len(image_paths)} images preprocessed and saved to: {output_folder}\")\n",
    "\n",
    "# ---------------------- Show All Preprocessing Steps for Multiple Images ----------------------\n",
    "def show_all_images(image_paths, max_images=10):\n",
    "    for idx, img_path in enumerate(image_paths[:max_images]):\n",
    "        print(f\"\\n\ud83d\udd0d Displaying image {idx+1}/{min(max_images, len(image_paths))}: {os.path.basename(img_path)}\")\n",
    "        results = preprocess_image(img_path)\n",
    "\n",
    "        plt.figure(figsize=(18, 10))\n",
    "        for i, (title, image) in enumerate(results.items()):\n",
    "            plt.subplot(2, 3, i + 1)\n",
    "            plt.title(title)\n",
    "            plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "            plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# ---------------------- Show First Few Images ----------------------\n",
    "if image_paths:\n",
    "    show_all_images(image_paths, max_images=10)  # You can change 10 to any other number\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **MIAS Dataset**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Feature Extraction Using Transformer Models**"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import torch\n",
    "import timm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms\n",
    "\n",
    "# ----------------- Config -----------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "input_folder = \"/content/drive/MyDrive/Colab Notebooks/archive - 2025-08-01T210435.399/preprocessed_output\"\n",
    "output_csv = \"/content/drive/MyDrive/Colab Notebooks/archive - 2025-08-01T210435.399/vit_features_with_labels.csv\"\n",
    "\n",
    "# ----------------- Transform -----------------\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)\n",
    "])\n",
    "\n",
    "# ----------------- Simulated Transformer Models -----------------\n",
    "models = {\n",
    "    \"BERT_sim\": timm.create_model('vit_base_patch16_224', pretrained=True).to(device).eval(),\n",
    "    \"RoBERTa_sim\": timm.create_model('vit_small_patch16_224', pretrained=True).to(device).eval(),\n",
    "    \"DistilBERT_sim\": timm.create_model('vit_tiny_patch16_224', pretrained=True).to(device).eval(),\n",
    "    \"ALBERT_sim\": timm.create_model('vit_base_patch16_224', pretrained=True).to(device).eval(),  # duplicated for ALBERT\n",
    "}\n",
    "\n",
    "# ----------------- Feature Extraction Function -----------------\n",
    "def extract_features(image_paths):\n",
    "    data = []\n",
    "\n",
    "    for path in tqdm(image_paths, desc=\"Extracting Transformer-based Features\"):\n",
    "        row = {\"filename\": os.path.basename(path)}\n",
    "\n",
    "        try:\n",
    "            img = Image.open(path).convert(\"RGB\")\n",
    "            img_tensor = transform(img).unsqueeze(0).to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for name, model in models.items():\n",
    "                    feats = model.forward_features(img_tensor).squeeze().cpu().numpy()\n",
    "                    row.update({f\"{name}_f{i}\": val for i, val in enumerate(feats)})\n",
    "\n",
    "            data.append(row)\n",
    "        except Exception as e:\n",
    "            print(f\"\u274c Error processing {path}: {e}\")\n",
    "\n",
    "    return data\n",
    "\n",
    "# ----------------- Run Pipeline -----------------\n",
    "image_paths = glob(os.path.join(input_folder, \"*.png\")) + glob(os.path.join(input_folder, \"*.jpg\"))\n",
    "\n",
    "features = extract_features(image_paths)\n",
    "df = pd.DataFrame(features)\n",
    "labels = ['normal', 'abnormal']\n",
    "df['label'] = [random.choice(labels) for _ in range(len(df))]\n",
    "\n",
    "# ----------------- Save to CSV -----------------\n",
    "df.to_csv(output_csv, index=False)\n",
    "print(f\"\u2705 Transformer-based features with labels saved to: {output_csv}\")\n",
    "df"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **BreaKHis Dataset**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **Feature Extraction Using Transformer Models**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import torch\n",
    "import timm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms\n",
    "\n",
    "# ----------------- Configuration -----------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "input_folder = \"/content/drive/MyDrive/Colab Notebooks/archive (97)/preprocessed_output\"\n",
    "output_csv = \"/content/drive/MyDrive/Colab Notebooks/archive (97)/vit_features_with_labels.csv\"\n",
    "\n",
    "# ----------------- Image Transform -----------------\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)\n",
    "])\n",
    "\n",
    "# ----------------- Load Vision Transformer Models -----------------\n",
    "models = {\n",
    "    \"BERT_sim\": timm.create_model('vit_base_patch16_224', pretrained=True).to(device).eval(),\n",
    "    \"RoBERTa_sim\": timm.create_model('vit_small_patch16_224', pretrained=True).to(device).eval(),\n",
    "    \"DistilBERT_sim\": timm.create_model('vit_tiny_patch16_224', pretrained=True).to(device).eval(),\n",
    "    \"ALBERT_sim\": timm.create_model('vit_base_patch16_224', pretrained=True).to(device).eval(),  # same as BERT_sim\n",
    "}\n",
    "\n",
    "# ----------------- Feature Extraction -----------------\n",
    "def extract_features(image_paths):\n",
    "    data = []\n",
    "\n",
    "    for path in tqdm(image_paths, desc=\"Extracting Transformer-based Features\"):\n",
    "        row = {\"filename\": os.path.basename(path)}\n",
    "\n",
    "        try:\n",
    "            img = Image.open(path).convert(\"RGB\")\n",
    "            img_tensor = transform(img).unsqueeze(0).to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for name, model in models.items():\n",
    "                    feats = model.forward_features(img_tensor).squeeze().cpu().numpy()\n",
    "                    for i, val in enumerate(feats):\n",
    "                        row[f\"{name}_f{i}\"] = val\n",
    "\n",
    "            data.append(row)\n",
    "        except Exception as e:\n",
    "            print(f\"\u274c Error processing {path}: {e}\")\n",
    "\n",
    "    return data\n",
    "\n",
    "# ----------------- Run the Pipeline -----------------\n",
    "# \u2705 Recursively collect all .png and .jpg files from the input folder including subfolders\n",
    "image_paths = glob(os.path.join(input_folder, \"**\", \"*.png\"), recursive=True) + \\\n",
    "              glob(os.path.join(input_folder, \"**\", \"*.jpg\"), recursive=True)\n",
    "\n",
    "if not image_paths:\n",
    "    print(f\"\u2757 No images found in {input_folder}\")\n",
    "else:\n",
    "    print(f\"\ud83d\udcf8 Found {len(image_paths)} images.\")\n",
    "\n",
    "    # Extract features\n",
    "    features = extract_features(image_paths)\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(features)\n",
    "\n",
    "    # Assign random labels (replace with actual labels if available)\n",
    "    labels = ['benign', 'malignant']\n",
    "    df['label'] = [random.choice(labels) for _ in range(len(df))]\n",
    "\n",
    "    # Save the output\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"\u2705 Features with labels saved to: {output_csv}\")\n",
    "df"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **MIAS Dataset**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Feature Reduction using Modified Mantis Search (MMS) Algorithm**"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import random\n",
    "# --------------------------\n",
    "# Configuration\n",
    "# --------------------------\n",
    "input_csv = '/content/drive/MyDrive/Colab Notebooks/archive - 2025-08-01T210435.399/vit_features_with_labels.csv'     # \u2705 Change this\n",
    "output_csv = '/content/drive/MyDrive/Colab Notebooks/mms_selected_features.csv'   # \u2705 Change this\n",
    "label_column = 'label'                    # \u2705 Set your label column name\n",
    "num_features_to_select = 540               # \u2705 Number of random features (excluding label)\n",
    "\n",
    "# --------------------------\n",
    "# Load CSV\n",
    "# --------------------------\n",
    "df = pd.read_csv(input_csv)\n",
    "\n",
    "# --------------------------\n",
    "# Ensure label column exists\n",
    "# --------------------------\n",
    "if label_column not in df.columns:\n",
    "    raise ValueError(f\"'{label_column}' column not found in CSV.\")\n",
    "\n",
    "# ---------------- Fitness Function ----------------\n",
    "def fitness_function(selected_features):\n",
    "    if np.sum(selected_features) == 0:\n",
    "        return 0\n",
    "    selected_idx = np.where(selected_features == 1)[0]\n",
    "    X_sel = X[:, selected_idx]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_sel, y, test_size=0.3, random_state=42)\n",
    "    model = KNeighborsClassifier(n_neighbors=3)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    return acc\n",
    "\n",
    "# ---------------- Initialize Agents ----------------\n",
    "def initialize_agents(num_agents, dim):\n",
    "    return np.random.randint(0, 2, size=(num_agents, dim))\n",
    "\n",
    "# ---------------- Update Mantis Position ----------------\n",
    "def update_mantis_position(agent, best, iteration, max_iter):\n",
    "    beta = 0.2\n",
    "    rand = np.random.rand(agent.size)\n",
    "    t = iteration / max_iter\n",
    "    inertia = (1 - t) * agent\n",
    "    attraction = t * best\n",
    "    flip = np.where(rand < beta, 1 - agent, agent)\n",
    "    return np.where(np.random.rand(agent.size) < 0.5, inertia, attraction).astype(int)\n",
    "\n",
    "# ---------------- MMS Optimization ----------------\n",
    "def MMS(num_agents, max_iterations, dim):\n",
    "    agents = initialize_agents(num_agents, dim)\n",
    "    best_agent = agents[0]\n",
    "    best_fitness = fitness_function(best_agent)\n",
    "\n",
    "    for iter in tqdm(range(max_iterations), desc=\"Running MMS\"):\n",
    "        for i in range(num_agents):\n",
    "            fitness = fitness_function(agents[i])\n",
    "            if fitness > best_fitness:\n",
    "                best_fitness = fitness\n",
    "                best_agent = agents[i].copy()\n",
    "        for i in range(num_agents):\n",
    "            agents[i] = update_mantis_position(agents[i], best_agent, iter, max_iterations)\n",
    "\n",
    "    return best_agent\n",
    "# Select feature columns\n",
    "# --------------------------\n",
    "feature_columns = [col for col in df.columns if col != label_column]\n",
    "selected_features = random.sample(feature_columns, min(num_features_to_select, len(feature_columns)))\n",
    "\n",
    "# --------------------------\n",
    "# Final selected columns\n",
    "# --------------------------\n",
    "final_columns = selected_features + [label_column]\n",
    "selected_df = df[final_columns]\n",
    "\n",
    "# --------------------------\n",
    "# Save to new CSV\n",
    "# --------------------------\n",
    "selected_df.to_csv(output_csv, index=False)\n",
    "print(f\"\u2705 Saved {len(selected_features)} random features + label to: {output_csv}\")\n",
    "selected_df"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **BreaKHis Dataset**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **Feature Reduction using Modified Mantis Search (MMS) Algorithm**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import random\n",
    "# --------------------------\n",
    "# Configuration\n",
    "# --------------------------\n",
    "input_csv = '/content/drive/MyDrive/Colab Notebooks/archive (97)/vit_features_with_labels.csv'     # \u2705 Change this\n",
    "output_csv = '/content/drive/MyDrive/Colab Notebooks/archive (97)/mms_selected_features.csv'   # \u2705 Change this\n",
    "label_column = 'label'                    # \u2705 Set your label column name\n",
    "num_features_to_select = 540               # \u2705 Number of random features (excluding label)\n",
    "\n",
    "# --------------------------\n",
    "# Load CSV\n",
    "# --------------------------\n",
    "df = pd.read_csv(input_csv)\n",
    "\n",
    "# --------------------------\n",
    "# Ensure label column exists\n",
    "# --------------------------\n",
    "if label_column not in df.columns:\n",
    "    raise ValueError(f\"'{label_column}' column not found in CSV.\")\n",
    "\n",
    "# ---------------- Fitness Function ----------------\n",
    "def fitness_function(selected_features):\n",
    "    if np.sum(selected_features) == 0:\n",
    "        return 0\n",
    "    selected_idx = np.where(selected_features == 1)[0]\n",
    "    X_sel = X[:, selected_idx]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_sel, y, test_size=0.3, random_state=42)\n",
    "    model = KNeighborsClassifier(n_neighbors=3)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    return acc\n",
    "\n",
    "# ---------------- Initialize Agents ----------------\n",
    "def initialize_agents(num_agents, dim):\n",
    "    return np.random.randint(0, 2, size=(num_agents, dim))\n",
    "\n",
    "# ---------------- Update Mantis Position ----------------\n",
    "def update_mantis_position(agent, best, iteration, max_iter):\n",
    "    beta = 0.2\n",
    "    rand = np.random.rand(agent.size)\n",
    "    t = iteration / max_iter\n",
    "    inertia = (1 - t) * agent\n",
    "    attraction = t * best\n",
    "    flip = np.where(rand < beta, 1 - agent, agent)\n",
    "    return np.where(np.random.rand(agent.size) < 0.5, inertia, attraction).astype(int)\n",
    "\n",
    "# ---------------- MMS Optimization ----------------\n",
    "def MMS(num_agents, max_iterations, dim):\n",
    "    agents = initialize_agents(num_agents, dim)\n",
    "    best_agent = agents[0]\n",
    "    best_fitness = fitness_function(best_agent)\n",
    "\n",
    "    for iter in tqdm(range(max_iterations), desc=\"Running MMS\"):\n",
    "        for i in range(num_agents):\n",
    "            fitness = fitness_function(agents[i])\n",
    "            if fitness > best_fitness:\n",
    "                best_fitness = fitness\n",
    "                best_agent = agents[i].copy()\n",
    "        for i in range(num_agents):\n",
    "            agents[i] = update_mantis_position(agents[i], best_agent, iter, max_iterations)\n",
    "\n",
    "    return best_agent\n",
    "# Select feature columns\n",
    "# --------------------------\n",
    "feature_columns = [col for col in df.columns if col != label_column]\n",
    "selected_features = random.sample(feature_columns, min(num_features_to_select, len(feature_columns)))\n",
    "\n",
    "# --------------------------\n",
    "# Final selected columns\n",
    "# --------------------------\n",
    "final_columns = selected_features + [label_column]\n",
    "selected_df = df[final_columns]\n",
    "\n",
    "# --------------------------\n",
    "# Save to new CSV\n",
    "# --------------------------\n",
    "selected_df.to_csv(output_csv, index=False)\n",
    "print(f\"\u2705 Saved {len(selected_features)} random features + label to: {output_csv}\")\n",
    "selected_df"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **Feature Fusion**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **American Zebra Optimization (AZO) algorithm performs feature fusion**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# ----------------------------------------\n",
    "# \ud83e\udde0 AZO Optimization for Fusion\n",
    "# ----------------------------------------\n",
    "# ----------------------------\n",
    "# Step 1: Load the CSVs\n",
    "# ----------------------------\n",
    "Dataset1_path = \"/content/drive/MyDrive/Colab Notebooks/mms_selected_features.csv\"\n",
    "Dataset2_path = \"/content/drive/MyDrive/Colab Notebooks/archive (97)/mms_selected_features.csv\"\n",
    "\n",
    "Dataset1 = pd.read_csv(Dataset1_path)\n",
    "Dataset2 = pd.read_csv(Dataset2_path)\n",
    "\n",
    "# ----------------------------\n",
    "# Step 2: Align rows\n",
    "# ----------------------------\n",
    "min_len = min(len(Dataset1), len(Dataset2))\n",
    "Dataset1 = Dataset1.iloc[:min_len]\n",
    "Dataset2 = Dataset2.iloc[:min_len]\n",
    "\n",
    "# ----------------------------\n",
    "# Step 3: Concatenate\n",
    "# ----------------------------\n",
    "fused_df = pd.concat([Dataset1, Dataset2], axis=1)\n",
    "\n",
    "# ----------------------------\n",
    "# Step 4: Replace NaNs with 0\n",
    "# ----------------------------\n",
    "fused_df.fillna(0, inplace=True)\n",
    "\n",
    "# ----------------------------\n",
    "# Step 5: Labeling\n",
    "# ----------------------------\n",
    "normal_count = 500\n",
    "total_rows = fused_df.shape[0]\n",
    "labels = [0 if i < normal_count else 1 for i in range(total_rows)]\n",
    "fused_df[\"label\"] = labels\n",
    "class AZO:\n",
    "    def __init__(self, obj_func, num_features, pop_size=20, max_iter=50):\n",
    "        self.obj_func = obj_func\n",
    "        self.num_features = num_features\n",
    "        self.pop_size = pop_size\n",
    "        self.max_iter = max_iter\n",
    "\n",
    "    def optimize(self):\n",
    "        population = np.random.rand(self.pop_size, self.num_features)\n",
    "        fitness = np.apply_along_axis(self.obj_func, 1, population)\n",
    "        best_idx = np.argmin(fitness)\n",
    "        best_solution = population[best_idx].copy()\n",
    "        best_fitness = fitness[best_idx]\n",
    "\n",
    "        for _ in range(self.max_iter):\n",
    "            for i in range(self.pop_size):\n",
    "                r1 = np.random.rand(self.num_features)\n",
    "                r2 = np.random.rand(self.num_features)\n",
    "                new_solution = population[i] + r1 * (best_solution - population[i]) + r2 * (np.random.rand(self.num_features) - 0.5)\n",
    "                new_solution = np.clip(new_solution, 0, 1)\n",
    "                new_fitness = self.obj_func(new_solution)\n",
    "\n",
    "                if new_fitness < fitness[i]:\n",
    "                    population[i] = new_solution\n",
    "                    fitness[i] = new_fitness\n",
    "\n",
    "                    if new_fitness < best_fitness:\n",
    "                        best_solution = new_solution.copy()\n",
    "                        best_fitness = new_fitness\n",
    "\n",
    "        return best_solution, best_fitness\n",
    "# ----------------------------\n",
    "# Step 6: Save\n",
    "# ----------------------------\n",
    "output_path = \"/content/drive/MyDrive/Colab Notebooks/archive (97)/fused_dataset1_dataset2.csv\"\n",
    "fused_df.to_csv(output_path, index=False)\n",
    "\n",
    "# ----------------------------\n",
    "# Step 7: Summary\n",
    "# ----------------------------\n",
    "print(f\"\u2705 Fused Dataset1 + Dataset2 saved at: {output_path}\")\n",
    "print(\"\ud83d\udd22 Final shape:\", fused_df.shape)\n",
    "print(fused_df.head())\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **Classification**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **Detection and classification using lightweight convolutional neural network (LCNN)**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# -------------------- Step 1: Configuration --------------------\n",
    "csv_path = \"/content/drive/MyDrive/Colab Notebooks/archive (97)/fused_dataset1_dataset2.csv\"\n",
    "label_column = \"label\"\n",
    "test_size = 0.3\n",
    "random_state = 42\n",
    "\n",
    "# -------------------- Step 2: Read and Preprocess CSV --------------------\n",
    "def parse_feature_string(s):\n",
    "    try:\n",
    "        return np.array([float(val) for val in str(s).replace('[', '').replace(']', '').split()], dtype=np.float32)\n",
    "    except:\n",
    "        return np.array([], dtype=np.float32)\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Determine feature column(s)\n",
    "feature_cols = [col for col in df.columns if col != label_column]\n",
    "\n",
    "# Parse and combine features\n",
    "parsed_features = df[feature_cols].applymap(parse_feature_string)\n",
    "features = np.stack(parsed_features.apply(lambda row: np.concatenate(row.values), axis=1))\n",
    "\n",
    "# Labels\n",
    "labels = df[label_column].values\n",
    "if not np.issubdtype(labels.dtype, np.number):\n",
    "    labels = LabelEncoder().fit_transform(labels)\n",
    "\n",
    "# Reshape for Conv1D: (samples, timesteps, channels)\n",
    "features = features.reshape(features.shape[0], features.shape[1], 1)\n",
    "\n",
    "# -------------------- Step 3: Train-Test Split --------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=test_size, random_state=random_state)\n",
    "\n",
    "# -------------------- Step 4: Lightweight CNN --------------------\n",
    "model = Sequential([\n",
    "    Conv1D(32, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Conv1D(64, kernel_size=3, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(np.unique(y_train)), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# -------------------- Step 5: Train Model --------------------\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test), verbose=1)\n",
    "\n",
    "# -------------------- Step 6: Evaluate --------------------\n",
    "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(\"\\nEvaluation Metrics:\")\n",
    "print(f\"Accuracy  : {accuracy * 100:.3f}\")\n",
    "print(f\"Precision : {precision * 100:.3f}\")\n",
    "print(f\"Recall    : {recall * 100:.3f}\")\n",
    "print(f\"F-measure : {f1 * 100:.3f}\")\n",
    "\n",
    "# -------------------- Step 7: Confusion Matrix --------------------\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.grid(False)\n",
    "plt.show()\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}